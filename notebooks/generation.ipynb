{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "%config IPCompleter.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed, StoppingCriteria, StoppingCriteriaList\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"codeparrot/codeparrot-small\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codeparrot/codeparrot-small\")\n",
    "# human_eval = load_dataset(\"openai_humaneval\", split='test').filter(lambda x: len(x['canonical_solution'].split('\\n'))<3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOF_STRINGS = [\"\\nclass\", \"\\ndef\", \"\\n@\", \"\\nprint\", \"\\nif\", \"\\n>\"]\n",
    "EOF_SPLIT_REGEX = \"(\" + \"|\".join(EOF_STRINGS) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_run(tokenizer,\n",
    "                 model,\n",
    "                 prompt,\n",
    "                 temperature=0.6,\n",
    "                 top_k=50,\n",
    "                 top_p=1.0,\n",
    "                 typical_p=1.0,\n",
    "                 do_sample=False,\n",
    "                 num_beams=1,\n",
    "                 num_beam_groups=1,\n",
    "                 num_return_sequences=1,\n",
    "                 num_tokens_to_generate=128):\n",
    "    \n",
    "    len_prompt = len(tokenizer.tokenize(prompt))\n",
    "    tokenized_promnpt = tokenizer(prompt, return_tensors='pt', padding=True)\n",
    "    input_ids = tokenized_promnpt.input_ids.to(device)\n",
    "    attention_mask = tokenized_promnpt.attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        generation = model.generate(inputs=input_ids,\n",
    "                                    temperature=temperature,\n",
    "                                    top_k=top_k,\n",
    "                                    top_p=top_p,\n",
    "                                    typical_p=typical_p,\n",
    "                                    do_sample=do_sample, \n",
    "                                    num_beams=num_beams,\n",
    "                                    num_beam_groups=num_beam_groups,\n",
    "                                    max_length=len_prompt+num_tokens_to_generate, \n",
    "                                    num_return_sequences=num_return_sequences,\n",
    "                                   pad_token_id=tokenizer.eos_token_id)\n",
    "    generation = tokenizer.batch_decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return {'cleaned_generation':[prompt+re.split(EOF_SPLIT_REGEX, i[len(prompt):])[0] for i in generation],\n",
    "            'full_generation': generation,\n",
    "            'temperature':temperature,\n",
    "            'top_k': top_k,\n",
    "            'top_p':top_p,\n",
    "            'typical_p':typical_p,\n",
    "            'do_sample':do_sample,\n",
    "            'num_beams':num_beams,\n",
    "            'num_beam_groups':num_beam_groups,\n",
    "            'num_return_sequences':num_return_sequences,\n",
    "            'num_tokens_to_generate':num_tokens_to_generate,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [round(x * 0.1, 1) for x in range(1, 51)]\n",
    "top_p = [round(x * 0.1, 1) for x in range(1, 10)]\n",
    "typical_p = [round(x * 0.1, 1) for x in range(1, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480a77c063744154a9bb97f858e7cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17718c5fd8604a45b60d489a1d0a70b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2803e23dbe274238b6da34de06cfd955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88551c1754dc4f9cb6ff4519b4739d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcbb438047949b7b24513f97575c4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29ff5f415a04abd87cda9432776c638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e463298ba0346fab331c563f7cfbac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9906daf219461cbe9a07ee722a0d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e68113c1ab54f018e17ca197a86875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min, sys: 7min 29s, total: 25min 29s\n",
      "Wall time: 25min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "series_list = []\n",
    "for p in typical_p:\n",
    "    for row in tqdm(human_eval):\n",
    "        generation = generate_run(tokenizer, model, row['prompt'], temperature=1.4, \n",
    "                                  top_k=50, top_p=1.0, typical_p=p, do_sample=True, \n",
    "                                  num_beams=1, num_beam_groups=1, num_return_sequences=200,\n",
    "                                  num_tokens_to_generate=128)\n",
    "        series_list.append(pd.Series({**row, **generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(series_list)\n",
    "results.to_json('../runs/codeparrot-small/typical_p_sweep_temp_1.4.jsonl', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ndef sub(a,b):\\n    return a-b\\n\\ndef mul(a,b):\\n    return a*b\\n\\ndef div(a',\n",
       " '\\ndef sub(a,b):\\n    return a-b\\n\\ndef mul(a,b):\\n    return a*b\\n\\ndef div(a']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['full_generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate_run(tokenizer=tokenizer,\n",
    "                          model=model,\n",
    "                          prompt=\"\\ndef sub(a,b):\",\n",
    "                          temperature=t,\n",
    "                          num_beams=10,\n",
    "                          num_beam_groups=10,\n",
    "                          num_return_sequences=2,\n",
    "                          num_tokens_to_generate=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typ_p=0.1\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return KNNClassifier(k=k, n=n, n_class=1, alpha=0.5, gamma=0.1)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.1\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return KNNClassifier(k=k, n=n, n_classes=3, init='uniform',\n",
      "                         subsample=0.5, alpha=0.1, eta=0.001,\n",
      "                         alpha_init=0\n",
      "*********\n",
      "typ_p=0.1\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "*********\n",
      "typ_p=0.2\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return classifier.Classifier(n_estimators=n, max_depth=k,\n",
      "                                min_samples_split=n, random_state=42)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.2\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    # Classifier\n",
      "    n = n + 1\n",
      "    n = n + 1\n",
      "    # Classifier\n",
      "    clf = LinearSVC(C=1.0, kernel='rbf', probability=True, tol=1e-4,\n",
      "                    random_\n",
      "*********\n",
      "typ_p=0.2\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    # type: (int, int) -> Dict[str, int]\n",
      "    # This is the first time we run the classifier, and then we can use the\n",
      "    # classifier to train the classifier on the test set.\n",
      "    classifier = {\n",
      "*********\n",
      "typ_p=0.3\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    # TODO: remove this once we can have a way to get a better name\n",
      "    # for the classifier.\n",
      "    # TODO: add a test for this.\n",
      "    return KerasClassifier(n_classes=n, n_informative=10\n",
      "*********\n",
      "typ_p=0.3\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Builds a classifier that will be used for the training process.\n",
      "    \"\"\"\n",
      "    classifier = tf.keras.Sequential([\n",
      "        tf.keras.layers.Dense(n, activation='relu', kernel_initializer='glorot_\n",
      "*********\n",
      "typ_p=0.3\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return {'k': k, 'n': n}\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.4\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier that can be used to train a model.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        Number of classes.\n",
      "    n : int\n",
      "        Number of classifiers.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier : dict\n",
      "        Classifier.\n",
      "   \n",
      "*********\n",
      "typ_p=0.4\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"Build a classifier with n samples from the training set.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        Number of samples to generate.\n",
      "    n : int\n",
      "        Number of samples to generate.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier : Classifier\n",
      "        The\n",
      "*********\n",
      "typ_p=0.4\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier from the given k-fold cross-validation dataset.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        Number of folds.\n",
      "    n : int\n",
      "        Number of samples.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    clf : classifier\n",
      "        A\n",
      "*********\n",
      "typ_p=0.5\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier with n classes\n",
      "    \"\"\"\n",
      "    classifier = LinearSVC(random_state=0)\n",
      "    classifier.fit(X, y)\n",
      "    return classifier\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.5\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return classifier.Classifier(k, n)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.5\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier of the given k-dimensional data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        The number of features.\n",
      "    n : int\n",
      "        The number of classes.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier : numpy.ndarray\n",
      "        The\n",
      "*********\n",
      "typ_p=0.6\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return [\n",
      "        (1.0 - 0.5 * k, 1.0 - 0.5 * k),\n",
      "        (1.0 - 0.5 * k, 1.0 - 0.5 * k),\n",
      "        (1\n",
      "*********\n",
      "typ_p=0.6\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"Build classifier for n-dimensional data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        Number of classes.\n",
      "    n : int\n",
      "        Number of samples.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier : dict\n",
      "        Dictionary with classification information.\n",
      "    \"\"\"\n",
      "    return\n",
      "*********\n",
      "typ_p=0.6\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    # print k, n\n",
      "    # print 'build classifier'\n",
      "    classifier = tf.contrib.learn.DNNClassifier(\n",
      "        hidden_units=[n, n],\n",
      "        n_classes=k,\n",
      "        optimizer=tf.train.Adam\n",
      "*********\n",
      "typ_p=0.7\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier from a list of n classifiers.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        The number of classifiers.\n",
      "    n : int\n",
      "        The number of classifiers.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier : dict\n",
      "        A dictionary with the\n",
      "*********\n",
      "typ_p=0.7\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Builds a classifier using the specified parameters.\n",
      "    \"\"\"\n",
      "    return Classifier(k, n)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.7\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Build a classifier using a precomputed KNN classifier.\n",
      "    \"\"\"\n",
      "    from sklearn.metrics import classification_report\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    from sklearn.metrics import accuracy_score\n",
      "    from sklearn.metrics import f\n",
      "*********\n",
      "typ_p=0.8\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return KNeighborsClassifier(n_neighbors=n, weights=None, algorithm='auto',\n",
      "                               fit_intercept=True, normalize=False)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.8\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"Build classifier.\"\"\"\n",
      "    # Build classifier\n",
      "    classifier = keras.models.Sequential()\n",
      "    classifier.add(keras.layers.Dense(n, input_shape=(n,)))\n",
      "    classifier.add(keras.layers.Activation('relu'))\n",
      "*********\n",
      "typ_p=0.8\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    \"\"\"\n",
      "    Builds a classifier for the given k-fold data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    k : int\n",
      "        The number of classes to use.\n",
      "    n : int\n",
      "        The number of samples to use.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    classifier :\n",
      "*********\n",
      "typ_p=0.9\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return [\n",
      "        Classifier(k, n) for i in range(k)\n",
      "    ]\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.9\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    if k == 0:\n",
      "        return 'classifier'\n",
      "    elif k == 1:\n",
      "        return 'classifier_multi'\n",
      "    else:\n",
      "        raise ValueError(\"Unknown classification type %d\" % k)\n",
      "\n",
      "\n",
      "*********\n",
      "typ_p=0.9\n",
      "\n",
      "def build_classifier(k, n):\n",
      "    return classifier.Classifier(\n",
      "        k=k, n=n, max_iter=10, tol=1e-8, fit_intercept=True,\n",
      "        normalize=False, max_features=None, solver='lbfgs',\n",
      "*********\n",
      "CPU times: user 3.7 s, sys: 202 ms, total: 3.9 s\n",
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for typ_p in typical_p:\n",
    "    g = generate_run(tokenizer=tokenizer,\n",
    "                          model=model,\n",
    "                          prompt=\"\\ndef build_classifier(k, n):\",\n",
    "                          typical_p=typ_p,\n",
    "                          do_sample=True,\n",
    "                          num_return_sequences=3,\n",
    "                          num_tokens_to_generate=50)\n",
    "    for i in g['cleaned_generation']:\n",
    "        print(f\"{typ_p=}\")\n",
    "        print(i)\n",
    "        print(\"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def sub(a,b):\n",
      "    return a-b\n",
      "\n",
      "def mul(a,b):\n",
      "    return a*b\n",
      "\n",
      "def div(a\n",
      "*********\n",
      "\n",
      "def sub(a,b):\n",
      "    return a-b\n",
      "\n",
      "def mul(a,b):\n",
      "    return a*b\n",
      "\n",
      "def div(a\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "for g in a['full_generation']:\n",
    "    print(g)\n",
    "    print('*********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
