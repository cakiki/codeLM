{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "%config IPCompleter.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_tokens=tokenizer.tokenize(\"return maximum value\")\n",
    "code_tokens=tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  9232, 19220,  1640,   102,     6,   428,  3256,   114,    10,\n",
       "         15698,   428,    35,   671,    10,  1493,   671,   741,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"def max(a,b): if a>b: return a else return b\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    o = model(**tokenizer([\"def max(a,b): if a>b: return a else return b\", \"def min(i,j): if i>j: return i else return j\"], return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.pooler_output[0,:].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../code_datasets/code_crawl.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43448    import sys\\nimport pygame\\n \\npygame.init()\\n ...\n",
       "Name: code, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['language_name'] == 'Python'].sample()['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1136.000000\n",
       "mean      1081.649648\n",
       "std       1916.171263\n",
       "min          3.000000\n",
       "25%        245.750000\n",
       "50%        640.500000\n",
       "75%       1300.250000\n",
       "max      46867.000000\n",
       "Name: code, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['language_name'] == 'Python']['code'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> def duration(seconds):\n",
      "\tt= []\n",
      "\tfor dm in (60, 60, 24, 7):\n",
      "\t\tseconds, m = divmod(seconds, dm)\n",
      "\t\tt.append(m)\n",
      "\tt.append(seconds)\n",
      "\treturn ', '.join('%d %s' % (num, unit)\n",
      "\t\t\t for num, unit in zip(t[::-1], 'wk d hr min sec'.split())\n",
      "\t\t\t if num)\n",
      " \n",
      ">>> for seconds in [7259, 86400, 6000000]:\n",
      "\tprint(\"%7d sec = %s\" % (seconds, duration(seconds)))\n",
      " \n",
      " \n",
      "   7259 sec = 2 hr, 59 sec\n",
      "  86400 sec = 1 d\n",
      "6000000 sec = 9 wk, 6 d, 10 hr, 40 min\n",
      ">>> \n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9992])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(o.pooler_output[0,:].unsqueeze(0), o.pooler_output[1,:].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 328 ms, total: 1.66 s\n",
      "Wall time: 5.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.8903]), tensor([0.8903]), tensor([0.8903]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Precision, Recall, F1 = score([\"def max(a,b): if a>b: return a else return b\"], [\"def max(i,j): if i>j: return i else return j\"], \n",
    "                 model_type=\"microsoft/graphcodebert-base\", num_layers=12)\n",
    "Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 186 ms, total: 1.47 s\n",
      "Wall time: 5.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.8669]), tensor([0.8669]), tensor([0.8669]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Precision, Recall, F1 = score([\"def max(a,b): if a>b: return a else return b\"], [\"def min(i,j): if i<j: return i else return j\"], \n",
    "                 model_type=\"microsoft/graphcodebert-base\", num_layers=12)\n",
    "Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision.numpy()=array([0.8903439], dtype=float32), Recall=tensor([0.8903]), F1=tensor([0.8903])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Precision.numpy()=}, {Recall=}, {F1=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9680341], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset code_x_glue_cc_code_completion_line/python (download: 23.14 MiB, generated: 22.91 MiB, post-processed: Unknown size, total: 46.05 MiB) to /tf/data/cache/HF/datasets/code_x_glue_cc_code_completion_line/python/0.0.0/4ce8a216b87c5b130aad675f2bbf3612cc1f7fa5dbdc2fcb9c412765cf7830a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e76a12dbac417d92bb026cbe1aaf98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a974c24d1a14ddea66138ab0fcfd330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.97M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7216d8bdaf34d538a34775ca02dda45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset code_x_glue_cc_code_completion_line downloaded and prepared to /tf/data/cache/HF/datasets/code_x_glue_cc_code_completion_line/python/0.0.0/4ce8a216b87c5b130aad675f2bbf3612cc1f7fa5dbdc2fcb9c412765cf7830a7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a13d02a6604c768fc2b39c902b7588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset code_x_glue_cc_code_completion_line/java (download: 5.27 MiB, generated: 5.20 MiB, post-processed: Unknown size, total: 10.47 MiB) to /tf/data/cache/HF/datasets/code_x_glue_cc_code_completion_line/java/0.0.0/4ce8a216b87c5b130aad675f2bbf3612cc1f7fa5dbdc2fcb9c412765cf7830a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66f2501544a479ba89a98f5a65515be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0932f7f1984647924aaba9969d8d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/993k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624683d206547f7845b63860bd4aefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset code_x_glue_cc_code_completion_line downloaded and prepared to /tf/data/cache/HF/datasets/code_x_glue_cc_code_completion_line/java/0.0.0/4ce8a216b87c5b130aad675f2bbf3612cc1f7fa5dbdc2fcb9c412765cf7830a7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3a72f3561d49aca46ef45d524585ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_py = load_dataset(\"code_x_glue_cc_code_completion_line\", \"python\")\n",
    "datasert_j = load_dataset(\"code_x_glue_cc_code_completion_line\", \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b0c0aad995495fac5ab48dce141f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cf3e60f72a4d439f95b37497aab5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bloom = AutoModel.from_pretrained('bigscience/bloom-350m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> from __future__ import absolute_import \n",
      " import weakref \n",
      " import operator \n",
      " from . compat import threading , itertools_filterfalse \n",
      " from . import py2k \n",
      " import types \n",
      " EMPTY_SET = frozenset ( ) \n",
      " class KeyedTuple ( tuple ) : \n",
      " def __new__ ( cls , vals , labels = None ) : \n",
      " t = tuple . __new__ ( cls , vals ) \n",
      " t . _labels = [ ] \n",
      " if labels : \n",
      " t . __dict__ . update ( zip ( labels , vals ) ) \n",
      " t . _labels = labels \n",
      " return t \n",
      " def keys ( self ) : \n",
      " return [ l for l in self . _labels if l is not None ] \n",
      " @ property \n",
      " def _fields ( self ) : \n",
      " return tuple ( self . keys ( ) ) \n",
      " def _asdict ( self ) : \n",
      " return dict ( ( key , self . __dict__ [ key ] ) for key in self . keys ( ) ) \n",
      " class ImmutableContainer ( object ) : \n",
      " def _immutable ( self , * arg , ** kw ) : \n",
      " raise TypeError ( \"\" % self . __class__ . __name__ ) \n",
      " __delitem__ = __setitem__ = __setattr__ = _immutable \n",
      " class immutabledict ( ImmutableContainer , dict ) : \n",
      " clear = pop = popitem = setdefault = update = ImmutableContainer . _immutable \n",
      " def __new__ ( cls , * args ) : \n",
      " new = dict . __new__ ( cls ) \n",
      " dict . __init__ ( new , * args ) \n",
      " return new \n",
      " def __init__ ( self , * args ) : \n",
      " pass \n",
      " def __reduce__ ( self ) : \n",
      " return immutabledict , ( dict ( self ) , ) \n",
      " def union ( self , d ) : \n",
      " if not self : \n",
      " return immutabledict ( d ) \n",
      " else : \n",
      " d2 = immutabledict ( self ) \n",
      " dict . update ( d2 , d ) \n",
      " return d2 \n",
      " def __repr__ ( self ) : \n",
      " return \"\" % dict . __repr__ ( self ) \n",
      " class Properties ( object ) : \n",
      " def __init__ ( self , data ) : \n",
      " self . __dict__ [ '_data' ] = data \n",
      " def __len__ ( self ) : \n",
      " return len ( self . _data ) \n",
      " def __iter__ ( self ) : \n",
      " return iter ( list ( self . _data . values ( ) ) ) \n",
      " def __add__ ( self , other ) : \n",
      " return list ( self ) + list ( other ) \n",
      " def __setitem__ ( self , key , object ) : \n",
      " self . _data [ key ] = object \n",
      " def __getitem__ ( self , key ) : \n",
      " return self . _data [ key ] \n",
      " def __delitem__ ( self , key ) : \n",
      " del self . _data [ key ] \n",
      " def __setattr__ ( self , key , object ) : \n",
      " self . _data [ key ] = object \n",
      " def __getstate__ ( self ) : \n",
      " return { '_data' : self . __dict__ [ '_data' ] } \n",
      " def __setstate__ ( self , state ) : \n",
      " self . __dict__ [ '_data' ] = state [ '_data' ] \n",
      " def __getattr__ ( self , key ) : \n",
      " try : \n",
      " return self . _data [ key ] \n",
      " except KeyError : \n",
      " raise AttributeError ( key ) \n",
      " def __contains__ ( self , key ) : \n",
      " return key in self . _data \n",
      " def as_immutable ( self ) : \n",
      " return ImmutableProperties ( self . _data ) \n",
      " def update ( self , value ) : \n",
      " self . _data . update ( value ) \n",
      " def get ( self , key , default = None ) : \n",
      " if key in self : \n",
      " return self [ key ] \n",
      " else : \n",
      " return default \n",
      " def keys ( self ) : \n",
      " return list ( self . _data ) \n",
      " def values ( self ) : \n",
      " return list ( self . _data . values ( ) ) \n",
      " def items ( self ) : \n",
      " return list ( self . _data . items ( ) ) \n",
      " def has_key ( self , key ) : \n",
      " return key in self . _data \n",
      " def clear ( self ) : \n",
      " self . _data . clear ( ) \n",
      " class OrderedProperties ( Properties ) : \n",
      " def __init__ ( self ) : \n",
      " Properties . __init__ ( self , OrderedDict ( ) ) \n",
      " class ImmutableProperties ( ImmutableContainer , Properties ) : \n",
      " class OrderedDict ( dict ) : \n",
      " def __init__ ( self , ____sequence = None , ** kwargs ) : \n",
      " self . _list = [ ] \n",
      " if ____sequence is None : \n",
      " if kwargs : \n",
      " self . update ( ** kwargs ) \n",
      " else : \n",
      " self . update ( ____sequence , ** kwargs ) \n",
      " def clear ( self ) : \n",
      " self . _list = [ ] \n",
      " dict . clear ( self ) \n",
      " def copy ( self ) : \n",
      " return self . __copy__ ( ) \n",
      " def __copy__ ( self ) : \n",
      " return OrderedDict ( self ) \n",
      " def sort ( self , * arg , ** kw ) : \n",
      " self . _list . sort ( * arg , ** kw ) \n",
      " def update ( self , ____sequence = None , ** kwargs ) : \n",
      " if ____sequence is not None : \n",
      " if hasattr ( ____sequence , 'keys' ) : \n",
      " for key in ____sequence . keys ( ) : \n",
      " self . __setitem__ ( key , ____sequence [ key ] ) \n",
      " else : \n",
      " for key , value in ____sequence : \n",
      " self [ key ] = value \n",
      " if kwargs : \n",
      " self . update ( kwargs ) \n",
      " def setdefault ( self , key , value ) : \n",
      " if key not in self : \n",
      " self . __setitem__ ( key , value ) \n",
      " return value \n",
      " else : \n",
      " return self . __getitem__ ( key ) \n",
      " def __iter__ ( self ) : \n",
      " return iter ( self . _list ) \n",
      " def keys ( self ) : \n",
      " return list ( self ) \n",
      " def values ( self ) : \n",
      " return [ self [ key ] for key in self . _list ] \n",
      " def items ( self ) : \n",
      " return [ ( key , self [ key ] ) for key in self . _list ] \n",
      " if py2k : \n",
      " def itervalues ( self ) : \n",
      " return iter ( self . values ( ) ) \n",
      " def iterkeys ( self ) : \n",
      " return iter ( self ) \n",
      " def iteritems ( self ) : \n",
      " return iter ( self . items ( ) ) \n",
      " def __setitem__ ( self , key , object ) : \n",
      " if key not in self : \n",
      " try : \n",
      " self . _list . append ( key ) \n",
      " except AttributeError : \n",
      " self . _list = [ key ] \n",
      " dict . __setitem__ ( self , key , object ) \n",
      " def __delitem__ ( self , key ) : \n",
      " dict . __delitem__ ( self , key ) \n",
      " self . _list . remove ( key ) \n",
      " def pop ( self , key , * default ) : \n",
      " present = key in self \n",
      " value = dict . pop ( self , key , * default ) \n",
      " if present : \n",
      " self . _list . remove ( key ) \n",
      " return value \n",
      " def popitem ( self ) : \n",
      " item = dict . popitem ( self ) \n",
      " self . _list . remove ( item [ 0 ] ) \n",
      " return item \n",
      " class OrderedSet ( set ) : \n",
      " def __init__ ( self , d = None ) : \n",
      " set . __init__ ( self ) \n",
      " self . _list = [ ] \n",
      " if d is not None : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_py['train'][0]['input'].replace('<EOL>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
